{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 136, "column": 0}, "map": {"version":3,"sources":["file:///Users/saka2jp/saka2jp/realtime-voice-chat/client/lib/utils.ts"],"sourcesContent":["import { clsx, type ClassValue } from \"clsx\"\nimport { twMerge } from \"tailwind-merge\"\n\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs))\n}\n"],"names":[],"mappings":";;;AAAA;AACA;;;AAEO,SAAS,GAAG,GAAG,MAAoB;IACxC,OAAO,CAAA,GAAA,2JAAA,CAAA,UAAO,AAAD,EAAE,CAAA,GAAA,qIAAA,CAAA,OAAI,AAAD,EAAE;AACtB","debugId":null}},
    {"offset": {"line": 146, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 152, "column": 0}, "map": {"version":3,"sources":["file:///Users/saka2jp/saka2jp/realtime-voice-chat/client/components/ui/button.tsx"],"sourcesContent":["import * as React from \"react\"\nimport { cn } from \"@/lib/utils\"\n\nexport interface ButtonProps\n  extends React.ButtonHTMLAttributes<HTMLButtonElement> {\n  variant?: \"default\" | \"destructive\" | \"outline\" | \"secondary\" | \"ghost\" | \"link\"\n  size?: \"default\" | \"sm\" | \"lg\" | \"icon\"\n}\n\nconst Button = React.forwardRef<HTMLButtonElement, ButtonProps>(\n  ({ className, variant = \"default\", size = \"default\", ...props }, ref) => {\n    const baseStyles = \"inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-white transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-slate-950 focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50\"\n    \n    const variantStyles = {\n      default: \"bg-slate-900 text-slate-50 hover:bg-slate-900/90\",\n      destructive: \"bg-red-500 text-slate-50 hover:bg-red-500/90\",\n      outline: \"border border-slate-200 bg-white hover:bg-slate-100 hover:text-slate-900\",\n      secondary: \"bg-slate-100 text-slate-900 hover:bg-slate-100/80\",\n      ghost: \"hover:bg-slate-100 hover:text-slate-900\",\n      link: \"text-slate-900 underline-offset-4 hover:underline\"\n    }\n    \n    const sizeStyles = {\n      default: \"h-10 px-4 py-2\",\n      sm: \"h-9 rounded-md px-3\",\n      lg: \"h-11 rounded-md px-8\",\n      icon: \"h-10 w-10\"\n    }\n    \n    return (\n      <button\n        className={cn(\n          baseStyles,\n          variantStyles[variant],\n          sizeStyles[size],\n          className\n        )}\n        ref={ref}\n        {...props}\n      />\n    )\n  }\n)\nButton.displayName = \"Button\"\n\nexport { Button }"],"names":[],"mappings":";;;;AAAA;AACA;;;;AAQA,MAAM,uBAAS,CAAA,GAAA,qMAAA,CAAA,aAAgB,AAAD,EAC5B,CAAC,EAAE,SAAS,EAAE,UAAU,SAAS,EAAE,OAAO,SAAS,EAAE,GAAG,OAAO,EAAE;IAC/D,MAAM,aAAa;IAEnB,MAAM,gBAAgB;QACpB,SAAS;QACT,aAAa;QACb,SAAS;QACT,WAAW;QACX,OAAO;QACP,MAAM;IACR;IAEA,MAAM,aAAa;QACjB,SAAS;QACT,IAAI;QACJ,IAAI;QACJ,MAAM;IACR;IAEA,qBACE,8OAAC;QACC,WAAW,CAAA,GAAA,sHAAA,CAAA,KAAE,AAAD,EACV,YACA,aAAa,CAAC,QAAQ,EACtB,UAAU,CAAC,KAAK,EAChB;QAEF,KAAK;QACJ,GAAG,KAAK;;;;;;AAGf;AAEF,OAAO,WAAW,GAAG","debugId":null}},
    {"offset": {"line": 189, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 195, "column": 0}, "map": {"version":3,"sources":["file:///Users/saka2jp/saka2jp/realtime-voice-chat/client/components/AudioRecorder.tsx"],"sourcesContent":["import { useState, useEffect, useRef } from 'react';\nimport { io, Socket } from 'socket.io-client';\nimport { Button } from '@/components/ui/button';\nimport { Mic, Square, Speaker } from 'lucide-react';\n\nexport default function AudioRecorder() {\n  const [isRecording, setIsRecording] = useState(false);\n  const [isConnected, setIsConnected] = useState(false);\n  const [responseText, setResponseText] = useState<string>('');\n  const socketRef = useRef<Socket | null>(null);\n  const mediaRecorderRef = useRef<MediaRecorder | null>(null);\n  const audioContextRef = useRef<AudioContext | null>(null);\n\n  useEffect(() => {\n    // Setup socket connection\n    const socket = io(process.env.NEXT_PUBLIC_API_URL || 'http://localhost:4000');\n    \n    socket.on('connect', () => {\n      console.log('Socket connected!');\n      setIsConnected(true);\n    });\n    \n    socket.on('disconnect', () => {\n      console.log('Socket disconnected');\n      setIsConnected(false);\n    });\n    \n    socket.on('voiceResponse', (data) => {\n      console.log('Received voice response');\n      if (data.text) {\n        setResponseText(data.text);\n      }\n      \n      if (data.audio) {\n        playAudioResponse(data.audio);\n      }\n    });\n    \n    socket.on('error', (error) => {\n      console.error('Socket error:', error);\n    });\n    \n    socketRef.current = socket;\n    \n    return () => {\n      socket.disconnect();\n    };\n  }, []);\n  \n  const startRecording = async () => {\n    try {\n      if (!isConnected) {\n        console.error('Not connected to server');\n        return;\n      }\n      \n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      \n      // Initialize AudioContext\n      audioContextRef.current = new AudioContext();\n      \n      // Initialize MediaRecorder\n      const mediaRecorder = new MediaRecorder(stream);\n      mediaRecorderRef.current = mediaRecorder;\n      \n      // Set up recording interval (e.g., send data every 250ms)\n      const recordingInterval = 250;\n      \n      // Tell server we're starting a voice stream\n      socketRef.current?.emit('startVoiceStream');\n      \n      // Handle data available from recorder\n      mediaRecorder.ondataavailable = async (event) => {\n        if (event.data.size > 0 && socketRef.current) {\n          // Convert blob to base64\n          const reader = new FileReader();\n          reader.onloadend = () => {\n            const base64data = (reader.result as string).split(',')[1];\n            // Send audio chunk to server\n            socketRef.current?.emit('voiceChunk', { audio: base64data });\n          };\n          reader.readAsDataURL(event.data);\n        }\n      };\n      \n      // Start recording\n      mediaRecorder.start(recordingInterval);\n      setIsRecording(true);\n      \n    } catch (error) {\n      console.error('Error starting recording:', error);\n    }\n  };\n  \n  const stopRecording = () => {\n    if (mediaRecorderRef.current && isRecording) {\n      mediaRecorderRef.current.stop();\n      \n      // Stop all audio tracks\n      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());\n      \n      // Tell server we're ending the voice stream\n      socketRef.current?.emit('endVoiceStream');\n      \n      setIsRecording(false);\n    }\n  };\n  \n  const playAudioResponse = async (base64Audio: string) => {\n    try {\n      // Create audio context if not exists\n      if (!audioContextRef.current) {\n        audioContextRef.current = new AudioContext();\n      }\n      \n      // Convert base64 to array buffer\n      const binaryString = window.atob(base64Audio);\n      const len = binaryString.length;\n      const bytes = new Uint8Array(len);\n      for (let i = 0; i < len; i++) {\n        bytes[i] = binaryString.charCodeAt(i);\n      }\n      \n      // Decode audio data\n      const audioBuffer = await audioContextRef.current.decodeAudioData(bytes.buffer);\n      \n      // Create audio source\n      const source = audioContextRef.current.createBufferSource();\n      source.buffer = audioBuffer;\n      source.connect(audioContextRef.current.destination);\n      source.start(0);\n    } catch (error) {\n      console.error('Error playing audio response:', error);\n    }\n  };\n\n  return (\n    <div className=\"flex flex-col items-center p-6 border rounded-lg shadow-md w-full max-w-md mx-auto\">\n      <h2 className=\"text-xl font-bold mb-4\">Real-time Voice Chat</h2>\n      \n      <div className=\"flex items-center justify-center space-x-4 mb-6\">\n        <Button\n          variant={isRecording ? \"destructive\" : \"default\"}\n          size=\"lg\"\n          onClick={isRecording ? stopRecording : startRecording}\n          disabled={!isConnected}\n          className=\"h-16 w-16 rounded-full\"\n        >\n          {isRecording ? <Square className=\"h-6 w-6\" /> : <Mic className=\"h-6 w-6\" />}\n        </Button>\n      </div>\n      \n      <div className=\"bg-slate-100 p-4 rounded-lg w-full min-h-[100px] mb-4\">\n        <p className=\"text-sm text-gray-500 mb-2\">Response:</p>\n        <p>{responseText || 'Waiting for response...'}</p>\n      </div>\n      \n      <div className=\"text-sm text-gray-500\">\n        Status: {isConnected ? 'Connected to server' : 'Disconnected'}\n      </div>\n    </div>\n  );\n}"],"names":[],"mappings":";;;;AAAA;AACA;AAAA;AACA;AACA;AAAA;;;;;;AAEe,SAAS;IACtB,MAAM,CAAC,aAAa,eAAe,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAE;IAC/C,MAAM,CAAC,aAAa,eAAe,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAE;IAC/C,MAAM,CAAC,cAAc,gBAAgB,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAU;IACzD,MAAM,YAAY,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAiB;IACxC,MAAM,mBAAmB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAwB;IACtD,MAAM,kBAAkB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAuB;IAEpD,CAAA,GAAA,qMAAA,CAAA,YAAS,AAAD,EAAE;QACR,0BAA0B;QAC1B,MAAM,SAAS,CAAA,GAAA,wLAAA,CAAA,KAAE,AAAD,EAAE,QAAQ,GAAG,CAAC,mBAAmB,IAAI;QAErD,OAAO,EAAE,CAAC,WAAW;YACnB,QAAQ,GAAG,CAAC;YACZ,eAAe;QACjB;QAEA,OAAO,EAAE,CAAC,cAAc;YACtB,QAAQ,GAAG,CAAC;YACZ,eAAe;QACjB;QAEA,OAAO,EAAE,CAAC,iBAAiB,CAAC;YAC1B,QAAQ,GAAG,CAAC;YACZ,IAAI,KAAK,IAAI,EAAE;gBACb,gBAAgB,KAAK,IAAI;YAC3B;YAEA,IAAI,KAAK,KAAK,EAAE;gBACd,kBAAkB,KAAK,KAAK;YAC9B;QACF;QAEA,OAAO,EAAE,CAAC,SAAS,CAAC;YAClB,QAAQ,KAAK,CAAC,iBAAiB;QACjC;QAEA,UAAU,OAAO,GAAG;QAEpB,OAAO;YACL,OAAO,UAAU;QACnB;IACF,GAAG,EAAE;IAEL,MAAM,iBAAiB;QACrB,IAAI;YACF,IAAI,CAAC,aAAa;gBAChB,QAAQ,KAAK,CAAC;gBACd;YACF;YAEA,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,YAAY,CAAC;gBAAE,OAAO;YAAK;YAEvE,0BAA0B;YAC1B,gBAAgB,OAAO,GAAG,IAAI;YAE9B,2BAA2B;YAC3B,MAAM,gBAAgB,IAAI,cAAc;YACxC,iBAAiB,OAAO,GAAG;YAE3B,0DAA0D;YAC1D,MAAM,oBAAoB;YAE1B,4CAA4C;YAC5C,UAAU,OAAO,EAAE,KAAK;YAExB,sCAAsC;YACtC,cAAc,eAAe,GAAG,OAAO;gBACrC,IAAI,MAAM,IAAI,CAAC,IAAI,GAAG,KAAK,UAAU,OAAO,EAAE;oBAC5C,yBAAyB;oBACzB,MAAM,SAAS,IAAI;oBACnB,OAAO,SAAS,GAAG;wBACjB,MAAM,aAAa,AAAC,OAAO,MAAM,CAAY,KAAK,CAAC,IAAI,CAAC,EAAE;wBAC1D,6BAA6B;wBAC7B,UAAU,OAAO,EAAE,KAAK,cAAc;4BAAE,OAAO;wBAAW;oBAC5D;oBACA,OAAO,aAAa,CAAC,MAAM,IAAI;gBACjC;YACF;YAEA,kBAAkB;YAClB,cAAc,KAAK,CAAC;YACpB,eAAe;QAEjB,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,6BAA6B;QAC7C;IACF;IAEA,MAAM,gBAAgB;QACpB,IAAI,iBAAiB,OAAO,IAAI,aAAa;YAC3C,iBAAiB,OAAO,CAAC,IAAI;YAE7B,wBAAwB;YACxB,iBAAiB,OAAO,CAAC,MAAM,CAAC,SAAS,GAAG,OAAO,CAAC,CAAA,QAAS,MAAM,IAAI;YAEvE,4CAA4C;YAC5C,UAAU,OAAO,EAAE,KAAK;YAExB,eAAe;QACjB;IACF;IAEA,MAAM,oBAAoB,OAAO;QAC/B,IAAI;YACF,qCAAqC;YACrC,IAAI,CAAC,gBAAgB,OAAO,EAAE;gBAC5B,gBAAgB,OAAO,GAAG,IAAI;YAChC;YAEA,iCAAiC;YACjC,MAAM,eAAe,OAAO,IAAI,CAAC;YACjC,MAAM,MAAM,aAAa,MAAM;YAC/B,MAAM,QAAQ,IAAI,WAAW;YAC7B,IAAK,IAAI,IAAI,GAAG,IAAI,KAAK,IAAK;gBAC5B,KAAK,CAAC,EAAE,GAAG,aAAa,UAAU,CAAC;YACrC;YAEA,oBAAoB;YACpB,MAAM,cAAc,MAAM,gBAAgB,OAAO,CAAC,eAAe,CAAC,MAAM,MAAM;YAE9E,sBAAsB;YACtB,MAAM,SAAS,gBAAgB,OAAO,CAAC,kBAAkB;YACzD,OAAO,MAAM,GAAG;YAChB,OAAO,OAAO,CAAC,gBAAgB,OAAO,CAAC,WAAW;YAClD,OAAO,KAAK,CAAC;QACf,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,iCAAiC;QACjD;IACF;IAEA,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC;gBAAG,WAAU;0BAAyB;;;;;;0BAEvC,8OAAC;gBAAI,WAAU;0BACb,cAAA,8OAAC,qIAAA,CAAA,SAAM;oBACL,SAAS,cAAc,gBAAgB;oBACvC,MAAK;oBACL,SAAS,cAAc,gBAAgB;oBACvC,UAAU,CAAC;oBACX,WAAU;8BAET,4BAAc,8OAAC,sMAAA,CAAA,SAAM;wBAAC,WAAU;;;;;6CAAe,8OAAC,gMAAA,CAAA,MAAG;wBAAC,WAAU;;;;;;;;;;;;;;;;0BAInE,8OAAC;gBAAI,WAAU;;kCACb,8OAAC;wBAAE,WAAU;kCAA6B;;;;;;kCAC1C,8OAAC;kCAAG,gBAAgB;;;;;;;;;;;;0BAGtB,8OAAC;gBAAI,WAAU;;oBAAwB;oBAC5B,cAAc,wBAAwB;;;;;;;;;;;;;AAIvD","debugId":null}},
    {"offset": {"line": 403, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 409, "column": 0}, "map": {"version":3,"sources":["file:///Users/saka2jp/saka2jp/realtime-voice-chat/client/app/page.tsx"],"sourcesContent":["import AudioRecorder from \"@/components/AudioRecorder\";\n\nexport default function Home() {\n  return (\n    <div className=\"min-h-screen p-8 flex flex-col items-center justify-center\">\n      <h1 className=\"text-3xl font-bold mb-8\">OpenAI Realtime Voice Chat</h1>\n      <AudioRecorder />\n    </div>\n  );\n}\n"],"names":[],"mappings":";;;;AAAA;;;AAEe,SAAS;IACtB,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC;gBAAG,WAAU;0BAA0B;;;;;;0BACxC,8OAAC,sIAAA,CAAA,UAAa;;;;;;;;;;;AAGpB","debugId":null}},
    {"offset": {"line": 440, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}